Initial Prompt-to-Render Flow (Draft Generation)
Phase 1: Initial Analysis (One Smart API Call)
User Input: You type your prompt (e.g., "A husky and a pug playing in the snow") into the main text area.
Generate Trigger: You click the "Generate" button, which initiates the handleGenerate function.
Consolidated Analysis: The app makes a single API call to the performInitialAnalysis agent. This one call performs two critical tasks simultaneously using a fast model (gemini-flash-lite-latest):
Text Analysis (Text SFX Artist logic): It intelligently checks if you've explicitly requested text (e.g., with quotes or a command). If you have, it designs a detailed "art direction brief" (textInfo) on how that text should physically appear in the scene. If not, it correctly determines no text is wanted. This is controlled by the "Process Text in Prompt" toggle.
Deep Analysis: It performs a deep analysis of your prompt's core concepts, breaking it down into a structured understanding of the subject, mood, lighting, environment, and style_intent.
Phase 2: Draft Prompt Creation
Draft Mode Decision: The app sees that you are in the default "Draft" mode.
Style Prompt Generation (Style Architect logic): The app calls the enhanceStyle agent in a special 'draft' mode. This agent takes your original prompt and the analysis from Phase 1 to create a new, concise prompt. It focuses on the three most impactful "Cinematic DNA" components—Lighting, Camera, and Color—to quickly generate a high-quality draft prompt. It also includes a non-negotiable instruction about whether text should be present, based on the textInfo.
Phase 3: Image Generation
Negative Prompt Generation: The getNegativePrompts function dynamically creates a set of negative keywords based on the analysis. For example, if the analysis detected a "portrait," it adds negative keywords to prevent common anatomical errors. If no text was detected, it adds keywords to prevent random words from appearing.
Parallel Image Generation: The app sends the draft prompt and negative prompts to the generateImage function, requesting four variations. This function uses a fast and efficient model (gemini-2.5-flash-image or gemini-3-pro-image-preview for text) to generate all four images in parallel.
Progressive Rendering: As each of the four draft images is completed by the API, it is immediately sent back to the app and "pops" into one of the placeholder slots on the canvas. A progress indicator updates in real-time (e.g., "Generating 2 of 4..."), providing you with immediate visual feedback instead of making you wait for all four to finish.
This entire flow is complete once all four draft images are displayed on the screen, ready for you to select one for editing or enhancement.
