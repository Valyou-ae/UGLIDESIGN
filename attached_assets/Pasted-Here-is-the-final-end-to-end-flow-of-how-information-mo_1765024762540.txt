Here is the final, end-to-end flow of how information moves through the application, from the moment you type your prompt to the final image being rendered on the canvas.
This system is designed as a multi-stage pipeline, where each "agent" or service processes the data and passes it to the next, ensuring the highest quality and accuracy at every step.
Phase 1: Initial Input & Deep Analysis
User Prompt: You enter your creative idea (e.g., "A coffee shop sign that says 'The Daily Grind'"), select your desired style, quality, and other settings. You click Generate.
Text Sentinel & Analysis Agent (performInitialAnalysis):
Your raw prompt is sent to a fast, lightweight AI model (gemini-flash-lite-latest).
This agent has two jobs:
Deep Analysis: It analyzes your prompt to understand the subject, mood, lighting, and environment.
Text Detection: It acts as a "Text Sentinel," strictly looking for explicit text requests. In this case, it accurately identifies "The Daily Grind".
Output: The agent returns a structured JSON object containing the scene analysis and the detected text "The Daily Grind". This data is saved for later.
Phase 2: Prompt Engineering & Placeholder Strategy
Style Architect (enhanceStyle):
This agent receives your original prompt, the analysis, and the detected text from Phase 1.
It enhances your prompt with "Cinematic DNA"—professional terms for lighting, camera work, and color grading.
Crucial Step for 100% Text Accuracy: Because text was detected, the agent adds a critical instruction to the prompt:
"...HIGHLY IMPORTANT: The image composition MUST include a clean, blank sign. This area must be intentionally and completely LEFT BLANK. DO NOT RENDER ANY TEXT..."
Output: The final, enhanced prompt is now engineered to create a beautiful image with a perfect, empty space for your text.
Phase 3: Image Generation & Display
Visual Synthesizer (generateImage):
The enhanced prompt (with the "leave blank" instruction) is sent to the powerful image generation model (gemini-3-pro-image-preview for high quality, gemini-2.5-flash-image for drafts).
The model generates the image as requested—a beautiful coffee shop scene with a blank wooden sign.
Output: The application receives the generated image data.
Draft Preview:
If you selected 'Draft' quality, you are presented with a 2x2 grid of four different interpretations of your prompt, all featuring a blank space for text.
Phase 4: Client-Side Text Compositing (The 100% Accuracy Step)
Enter the Editor: You click on one of the generated drafts.
This opens the editor view. The AI-generated image is loaded as the background layer onto a digital <canvas>.
Text Compositor Activates:
The application recalls the text "The Daily Grind" that was detected back in Phase 1.
It automatically creates a new text layer on the canvas with that content.
You now have full, direct control. Using the "Text Compositor" UI, you can:
Position: Drag the text exactly where you want it on the blank sign.
Style: Change the font, size, and color to be pixel-perfect.
Content: Edit the text if you change your mind.
Because you are rendering the text directly—not the AI—there are zero spelling errors and 100% accuracy.
Phase 5: Final Enhancement
Execute Enhance: Once you're happy with your composited image, you click Enhance.
The application captures the entire canvas (your image + your perfectly placed text) as a new, single image.
Master Refiner & Final Generation (runFinalGeneration & refineImage):
This new composited image is used as a strong visual reference for the final, high-quality generation.
The prompt is enhanced again for the highest quality settings.
The image model generates a new, high-resolution version.
Finally, a client-side Master Refiner agent applies a professional post-processing pass, adjusting sharpness, contrast, and color to achieve a cinematic, polished look.
Final Image Rendered: The final, high-quality, and text-perfect image is displayed on your screen, ready to be downloaded.