Initial Prompt-to-Render Flow (All Generations)
The entire process begins when you click "Generate". At this point, the application's logic branches depending on whether you are in "Draft" mode or requesting a high-quality "Final" image directly.
Phase 1: Universal Analysis (The "Brain")
This phase is the same for all generations and is designed for maximum efficiency.
User Input & Trigger: You type your prompt (e.g., "A husky and a pug playing in the snow") and click the Generate button. This calls the main handleGenerate function.
Consolidated Analysis (One Smart API Call): The application makes a single API call to the performInitialAnalysis agent. This agent is a highly efficient "Art Director's Assistant" that uses a fast model (gemini-flash-lite-latest) to perform two critical tasks simultaneously:
Task A: Text Analysis (Text SFX Artist Logic): It intelligently analyzes the prompt to determine if you explicitly want text rendered. It looks for commands like "add 'bliss'" or text in quotes. If it finds such a request (and the "Process Text" toggle is on), it designs a detailed "art direction brief" (textInfo) describing the text's physical material, lighting, and placement. If no text is requested, it correctly determines that no text is wanted and returns an empty result. This prevents "false positives."
Task B: Deep Analysis: At the same time, it performs a deep analysis of your prompt's core creative concepts. It structures this understanding into a PromptAnalysis object, identifying the subject (e.g., 'animal'), mood (e.g., 'playful'), lighting (e.g., 'natural daylight'), environment (e.g., 'outdoor snow'), and style_intent (e.g., 'photorealistic').
Context Lock: The result of this single API call—a comprehensive analysis of your intent—is stored. This becomes the foundational context for all subsequent steps in this generation.
Phase 2, Path A: The "Draft" Generation Pipeline
This is the default path, optimized for speed and iteration.
Draft Prompt Creation (Style Architect - Draft Mode): The enhanceStyle agent is called in a special, efficient 'draft' mode. Its goal is to create a high-quality but concise prompt. It takes your original prompt and the analysis from Phase 1 and enhances it by focusing on the three most impactful "Cinematic DNA" components: Lighting, Camera, and Color. It also receives a non-negotiable instruction about text (e.g., "The image must not contain any text.").
Negative Prompt Generation: A separate utility, getNegativePrompts, uses the analysis from Phase 1 to build a dynamic list of things to avoid. For example, since the subject is 'animal', it adds negative keywords to prevent anatomical errors. Since no text was requested, it adds keywords to prevent random words from appearing.
Parallel Image Generation (Visual Synthesizer): The application sends the draft prompt and negative prompts to the generateImage function, requesting four variations to be generated in parallel.
Model Selection: It uses a fast and efficient model: gemini-2.5-flash-image for image-only prompts, or automatically upgrades to the more powerful gemini-3-pro-image-preview if text is required, to ensure text accuracy even in drafts.
Progressive Rendering: This is a key UI feature. The system doesn't wait for all four images. As each of the four parallel generation tasks completes, the resulting image is immediately sent back to the app and "pops" into a placeholder slot on your screen. A progress indicator keeps you updated ("Generating 2 of 4...").
Phase 2, Path B: The "Final" Generation Pipeline
This path is taken if you select 'Standard', 'Premium', or 'Ultra' quality from the start. It is a much more intensive and sophisticated process.
Master Prompt Creation (Style Architect - Final Mode): The enhanceStyle agent is called in its full-power 'final' mode. This is its most complex task. It synthesizes multiple inputs: your original prompt, the deep analysis, the detailed text "art direction brief" (if any), the selected style preset (e.g., 'Cinematic'), and the chosen quality level (e.g., 'Ultra'). It draws heavily from its entire "Cinematic DNA" knowledge base (lighting, lenses, color grading, etc.) and adheres to all of its Prime Directives (Emotional Context, Physicality, De-duplication). The output is a single, dense, narrative-style master prompt that reads like a professional cinematographer's shot list.
Negative Prompt Generation: This step is identical to the draft pipeline, creating a tailored list of exclusions.
Orchestrated Image Generation (Visual Synthesizer): The generateImage function is called with the master prompt and a high-quality setting. It orchestrates the most powerful models available:
Primary Model: It first attempts to use imagen-4.0-generate-001, Google's state-of-the-art model for photorealism, for all non-text requests.
Specialist/Fallback Model: If Imagen 4.0 fails, or if the prompt requires text, the system automatically and seamlessly falls back to gemini-3-pro-image-preview to ensure the request is fulfilled with the highest possible quality and text accuracy.
AI Curation (Optional): If "AI Curation" is enabled, this step becomes even more rigorous. The system generates a larger batch of 8 candidate images "in the background." It then uses another fast AI agent (scoreImageQuality) to score each of the 8 images on composition, detail, and lighting. It then automatically selects and presents only the best results (e.g., the top 1 or 2) to you.
Post-Processing (Master Refiner): After the raw image is generated, the refineImage service is activated. This is a client-side "digital darkroom" that applies the final cinematic or photorealistic polish. It performs subtle, professional-grade adjustments like micro-contrast enhancement, shadow/highlight recovery, and color tinting based on the chosen preset (e.g., 'Photorealistic Polish').
Final Display: The final, fully refined and polished image (or images) appears on the canvas.